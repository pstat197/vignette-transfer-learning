---
title: "Transfer Learning Report"
author: "Bernie Graves, Kabir Snell, Ao Xu, Yuqing Xia"
format: html
editor: visual
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

## Abstract

Deep learning models can take a lot of time and resources to train, especially when there the amount of data gets large. Transfer learning lets you use pre-trained models on related but different tasks, saving time and resources while still using quality models. We used a pretrained model from Google called the Universal Sentence Encoder which essentially turns sentences into vectors. First you load the pretrained model and set the already trained layers to not be trainable. Then you make this pretrained model a layer in your deep learning model and train on your new data. Transfer learning has applications beyond sentiment analysis. It can be used with any pretrained deep learning model that you have access to.

## Dataset

## Data Preprocessing
